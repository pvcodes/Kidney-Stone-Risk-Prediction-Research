}
df_6mto1y <- joining(month_from = 6, month_to = 12)
df_6mto1y%>%
select(potholes, avg_rutting_depth, potholes_per_meter) %>%
pairs.panels(method = "spearman",
hist.col = "lightgreen",
density = TRUE,
ellipses = FALSE,
main = "Spearman Correlations (time lead between 6 months to 1 year)"
)
df_1yto2y <- joining(month_from = 12, month_to = 24)
df_1yto2y%>%
select(potholes, avg_rutting_depth, potholes_per_meter) %>%
pairs.panels(method = "spearman",
hist.col = "lightgreen",
density = TRUE,
ellipses = FALSE,
main = "Spearman Correlations (time lead between 1 year to 2 year)"
)
df_2yto4y <- joining(month_from = 24, month_to = 48)
df_2yto4y%>%
select(potholes, avg_rutting_depth, potholes_per_meter) %>%
pairs.panels(method = "spearman",
hist.col = "lightgreen",
density = TRUE,
ellipses = FALSE,
main = "Spearman Correlations (time lead between 2 to 3 years)"
)
## Covariance Analysis: Rutting and Potholes
# Assuming we're using the 'count_potholes' dataframe from earlier in the notebook
# If not, make sure to load or create it first
# Calculate covariance
cov_left_wheel <- cov(count_potholes$Potholes, count_potholes$left_wheelpath_mm)
cov_both_wheels <- cov(count_potholes$Potholes, count_potholes$both_wheelpaths_mm)
# Print results
cat("Covariance between Potholes and Left Wheelpath Rutting:", cov_left_wheel, "\n")
cat("Covariance between Potholes and Both Wheelpaths Rutting:", cov_both_wheels, "\n")
# Calculate correlation for comparison
cor_left_wheel <- cor(count_potholes$Potholes, count_potholes$left_wheelpath_mm)
cor_both_wheels <- cor(count_potholes$Potholes, count_potholes$both_wheelpaths_mm)
cat("\nCorrelation between Potholes and Left Wheelpath Rutting:", cor_left_wheel, "\n")
cat("Correlation between Potholes and Both Wheelpaths Rutting:", cor_both_wheels, "\n")
# Visualize the relationship
library(ggplot2)
ggplot(count_potholes, aes(x = left_wheelpath_mm, y = Potholes)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Relationship between Left Wheelpath Rutting and Potholes",
x = "Left Wheelpath Rutting (mm)",
y = "Number of Potholes")
ggplot(count_potholes, aes(x = both_wheelpaths_mm, y = Potholes)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "Relationship between Both Wheelpaths Rutting and Potholes",
x = "Both Wheelpaths Rutting (mm)",
y = "Number of Potholes")
library(tseries)
library(forecast)
library(feasts)
potholes_bydate <- potholes_df %>%
group_by(month_dispatched) %>%
summarise(sum_potholes = sum(potholes)) %>%
arrange(month_dispatched)
potholes_bydate
ts_potholes_bydate <- ts(potholes_bydate$sum_potholes,
start = c(2020, 7),
end = c(2024, 6),
frequency = 12)
# Plot
plot(ts_potholes_bydate,
main = "Potholes Over Time",
xlab = "Year",
ylab = "Number of Potholes")
lines(lowess(time(ts_potholes_bydate), ts_potholes_bydate), col="red")
legend("topleft", legend = c("Trend"),
col = c("red"), lty = 1)
unitroot_kpss(ts_potholes_bydate)
unitroot_kpss(diff(ts_potholes_bydate)) # first difference
decomp_potholes_bydate <- stl(ts_potholes_bydate, s.window = "periodic" )
plot(decomp_potholes_bydate,
main = "Decomposition of Number of Potholes between July 2020 and June 2024")
Looking at the overall trend, we noticed an increase in pothole numbers from 2020 to mid-2022, followed by a gradual decrease towards 2024. This could reflect changes in our maintenance strategies, road conditions, or even traffic patterns over time.
library(dplyr)
rutting <- read.csv("rutting_sh3_taranaki.csv")
head(rutting)
sum(duplicated(rutting))
potholes <- read.csv("potholes_sh3_taranaki.csv")
head(potholes)
sum(duplicated(potholes))
library(sqldf)
rutt_pot = sqldf("
SELECT r.*, month_dispatched
FROM potholes p JOIN rutting r
ON p.road_name = r.road_name AND p.start_m >= r.start_m AND p.end_m < r.end_m
")
head(rutt_pot)
#Check for duplicates
sum(duplicated(rutt_pot))
#how much is the percentage of duplicates
sum(duplicated(rutt_pot))/nrow(rutt_pot)
#NA values check
sum(is.na(rutt_pot))
library(psych)
library(lubridate)
count_potholes = sqldf("
SELECT survey_date, month_dispatched, road_name, start_m, end_m, left_wheelpath_mm, both_wheelpaths_mm, COUNT(*) AS 'Potholes'
FROM rutt_pot
GROUP BY road_name, start_m, end_m, left_wheelpath_mm, both_wheelpaths_mm
ORDER BY COUNT(*) DESC
")
joining <- function(month_from, month_to) {
count_potholes$survey_date <- as.Date(count_potholes$survey_date)
count_potholes$month_dispatched <- as.Date(count_potholes$month_dispatched)
count_potholes <- count_potholes %>%
filter(month_dispatched >= survey_date %m+% months(month_from+1) &
month_dispatched <= survey_date %m+% months(month_to+1)) %>%
return(joined_df)
}
joined <- joining(month_from = 38, month_to = 39)
joined%>%
select(Potholes, left_wheelpath_mm, both_wheelpaths_mm) %>%
pairs.panels(method = "spearman",
hist.col = "lightgreen",
density = TRUE,
ellipses = FALSE,
main = "Spearman Correlations"
)
library(zoo)
library(tidyverse)
rutting_df <- read.csv('rutting.csv')
potholes_df <- read.csv('potholes.csv')
joining <- function(month_from, month_to) {
rutting_df$survey_date <- as.Date(rutting_df$survey_date, format= "%d/%m/%Y")
joined_df <- potholes_df %>%
inner_join(rutting_df,
by = c("carrway_start_m", "carrway_end_m", "road_name")) %>%
filter(month_dispatched >= survey_date %m+% months(month_from+1) &
month_dispatched <= survey_date %m+% months(month_to+1)) %>%
mutate(length = carrway_end_m - carrway_start_m) %>%
mutate(potholes_per_meter = potholes/length) %>%
select(potholes, potholes_per_meter, avg_rutting_depth, length, month_dispatched, survey_date)
return(joined_df)
}
library(tseries)
library(forecast)
library(feasts)
potholes_bydate <- potholes_df %>%
group_by(month_dispatched) %>%
summarise(sum_potholes = sum(potholes)) %>%
arrange(month_dispatched)
potholes_bydate
ts_potholes_bydate <- ts(potholes_bydate$sum_potholes,
start = c(2020, 7),
end = c(2024, 6),
frequency = 12)
# Plot
plot(ts_potholes_bydate,
main = "Potholes Over Time",
xlab = "Year",
ylab = "Number of Potholes")
lines(lowess(time(ts_potholes_bydate), ts_potholes_bydate), col="red")
legend("topleft", legend = c("Trend"),
col = c("red"), lty = 1)
decomp_potholes_bydate <- stl(ts_potholes_bydate, s.window = "periodic" )
plot(decomp_potholes_bydate,
main = "Decomposition of Number of Potholes between July 2020 and June 2024")
unitroot_kpss(ts_potholes_bydate)
fit <- auto.arima(ts_potholes_bydate, seasonal = FALSE)
# Summary of the model
summary(fit)
# Diagnostic plots
checkresiduals(fit)
# Forecast
forecast_result <- forecast(fit, h = 12)
plot(forecast_result)
# Forecast
forecast_result <- forecast(fit, h = 12)  # Forecasting 12 periods ahead
plot(forecast_result)
fit <- auto.arima(ts_potholes_bydate, seasonal = FALSE)
# Summary of the model
summary(fit)
# Diagnostic plots
checkresiduals(fit)
fit <- auto.arima(ts_potholes_bydate, seasonal = TRUE)
forecast_result <- forecast(fit, h = 12)
plot(forecast_result)
fit <- auto.arima(ts_potholes_bydate, seasonal = FALSE)
forecast_result <- forecast(fit, h = 12)
plot(forecast_result)
fit <- auto.arima(ts_potholes_bydate, seasonal = TRUE)
forecast_result <- forecast(fit, h = 12)
plot(forecast_result)
![Prophet forecast for road segment 002-0018](segment_7.png)
![Prophet forecast for road segment 002-0073](segment_7.png)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
knitr::include_graphics("../figures/Methodology.pdf")
## 5.2.2 Synthetic Minority Over-sampling Technique (SMOTE)
To address class imbalance in the training set, we applied the Synthetic Minority Over-sampling Technique (SMOTE) [1]. SMOTE creates synthetic examples of the minority class, helping to prevent bias towards the majority class during model training. The SMOTE class from the imbalanced-learn library was utilized for this purpose.
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
# If you have a CSV file
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Read the CSV file
performance % kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# If you have a CSV file
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Read the CSV file
performance %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Create a styled table
performance %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
knitr::include_graphics("../../figures/shap_force_plot_instance_1.pdf")
knitr::include_graphics("../../EDA/figures/shap_force_plot_instance_1.pdf")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
knitr::include_graphics("../figures/combined_kidney_stones_graphs.pdf")
clear
clear()
install.packages("textit")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Create a styled table
performance %>%
select(-c(Mean.CV.Score,CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Create a styled table
performance %>%
select(-c(Mean.CV.Score,CV.Score.Std)) %>%
options("digits"=4)
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Create a styled table
performance %>%
select(-c(Mean.CV.Score,CV.Score.Std)) %>%
options("digits"=4)%>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Create a styled table
performance %>%
select(-c(Mean.CV.Score,CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
con_mat <- read.csv("../../EDA/results/confusion_mat.csv")
con_mat %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
con_mat <- read.csv("../../EDA/results/confusion_mat.csv")
col(con_mat) <- c("Model", "True Positive", "True Negative", "False Positive", "False Negative")
con_mat <- read.csv("../../EDA/results/confusion_mat.csv")
colnames(con_mat) <- c("Model", "True Positive", "True Negative", "False Positive", "False Negative")
con_mat %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
colnames(c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
colnames(c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC")) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
colnames(performance_rounded) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC")) %>%
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
colnames(performance_rounded) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC", "Mean CV Score", "CV Score Std")
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
colnames(performance_rounded) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC", "Mean CV Score", "CV Score Std")
# Create a styled table
performance_rounded %>%
select(-c(Mean CV Score, CV Score Std)) %>%
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
colnames(performance_rounded) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC", "Mean. CV.Score", "CV.Score.Std")
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
# Read the CSV file
performance <- read.csv("../../EDA/results/performance_metrics.csv")
# Function to round to 4 significant figures
round_signif <- function(x) {
if(is.numeric(x)) {
return(signif(x, 4))
} else {
return(x)
}
}
# Apply rounding to all columns except 'Model'
performance_rounded <- performance %>%
mutate(across(-Model, round_signif))
colnames(performance_rounded) <- c("Model", "Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC", "Mean.CV.Score", "CV.Score.Std")
# Create a styled table
performance_rounded %>%
select(-c(Mean.CV.Score, CV.Score.Std)) %>%
kable() %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
knitr::include_graphics("../../EDA/figures/shap_force_plot_instance1.pdf")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(kableExtra)
knitr::include_graphics("../../EDA/figures/shap_beeswarm_plot_top101.pdf")
getwd()
setwd("D:\Study\Year2\DATA301\Individual_Project\results\reports")
setwd("D:/Study/Year2/DATA301/Individual_Project/results/reports")
knitr::include_graphics("../../EDA/figures/shap_beeswarm_plot_top101.pdf")
knitr::include_graphics("../../EDA/figures/shap_beeswarm_plot_top101.pdf")
knitr::include_graphics("../../EDA/figures/shap_beeswarm_plot_top101.pdf")
